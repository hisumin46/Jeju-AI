{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from djitellopy import Tello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 122 - Tello instance was initialized. Host: '192.168.10.1'. Port: '8889'.\n",
      "[INFO] tello.py - 437 - Send command: 'command'\n",
      "[INFO] tello.py - 461 - Response command: 'ok'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배터리 83\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nono\\anaconda3\\envs\\test\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nono\\anaconda3\\envs\\test\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nono\\anaconda3\\envs\\test\\lib\\site-packages\\djitellopy\\tello.py\", line 1065, in update_frame\n",
      "    self.stop()\n",
      "  File \"c:\\Users\\nono\\anaconda3\\envs\\test\\lib\\site-packages\\djitellopy\\tello.py\", line 1074, in stop\n",
      "    self.worker.join()\n",
      "  File \"c:\\Users\\nono\\anaconda3\\envs\\test\\lib\\threading.py\", line 1008, in join\n",
      "    raise RuntimeError(\"cannot join current thread\")\n",
      "RuntimeError: cannot join current thread\n"
     ]
    }
   ],
   "source": [
    "# 배터리 체크\n",
    "def battery_check() : \n",
    "  drone = Tello()\n",
    "  drone.connect()\n",
    "\n",
    "  power = drone.get_battery()\n",
    "  if power < 30 : print(\"배터리 부족\", power)\n",
    "  else : print(\"배터리\", power)\n",
    "  drone.end()\n",
    "  return power\n",
    "battery_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 122 - Tello instance was initialized. Host: '192.168.10.1'. Port: '8889'.\n",
      "[INFO] tello.py - 437 - Send command: 'command'\n",
      "[INFO] tello.py - 461 - Response command: 'ok'\n",
      "[INFO] tello.py - 437 - Send command: 'streamon'\n",
      "[INFO] tello.py - 461 - Response streamon: 'ok'\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to grab first frame from video stream",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nono\\Desktop\\Github\\jeju_AI\\haarcascade model.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/haarcascade%20model.ipynb#ch0000002?line=30'>31</a>\u001b[0m   startCounter \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/haarcascade%20model.ipynb#ch0000002?line=32'>33</a>\u001b[0m \u001b[39m# 프레임 읽어오기\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/haarcascade%20model.ipynb#ch0000002?line=33'>34</a>\u001b[0m frame \u001b[39m=\u001b[39m drone\u001b[39m.\u001b[39;49mget_frame_read()\u001b[39m.\u001b[39mframe\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/haarcascade%20model.ipynb#ch0000002?line=34'>35</a>\u001b[0m \u001b[39m# 읽은 프레임 회색으로 스케일 변환\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/haarcascade%20model.ipynb#ch0000002?line=35'>36</a>\u001b[0m gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(frame, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n",
      "File \u001b[1;32mc:\\Users\\nono\\anaconda3\\envs\\test\\lib\\site-packages\\djitellopy\\enforce_types.py:54\u001b[0m, in \u001b[0;36menforce_types.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     53\u001b[0m     check_types(spec, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nono\\anaconda3\\envs\\test\\lib\\site-packages\\djitellopy\\tello.py:420\u001b[0m, in \u001b[0;36mTello.get_frame_read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackground_frame_read \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m     address \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_udp_video_address()\n\u001b[1;32m--> 420\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackground_frame_read \u001b[39m=\u001b[39m BackgroundFrameRead(\u001b[39mself\u001b[39;49m, address)  \u001b[39m# also sets self.cap\u001b[39;00m\n\u001b[0;32m    421\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackground_frame_read\u001b[39m.\u001b[39mstart()\n\u001b[0;32m    422\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackground_frame_read\n",
      "File \u001b[1;32mc:\\Users\\nono\\anaconda3\\envs\\test\\lib\\site-packages\\djitellopy\\tello.py:1048\u001b[0m, in \u001b[0;36mBackgroundFrameRead.__init__\u001b[1;34m(self, tello, address)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.05\u001b[39m)\n\u001b[0;32m   1047\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrabbed \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1048\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mFailed to grab first frame from video stream\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1050\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstopped \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworker \u001b[39m=\u001b[39m Thread(target\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_frame, args\u001b[39m=\u001b[39m(), daemon\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mException\u001b[0m: Failed to grab first frame from video stream"
     ]
    }
   ],
   "source": [
    "# 스타트flag\n",
    "startCounter = 1\n",
    "\n",
    "# 임계값 조절\n",
    "tolerance_x = 5\n",
    "tolerance_y = 5\n",
    "# 속도 한계값\n",
    "slowdown_threshold_x = 10\n",
    "slowdown_threshold_y = 10\n",
    "# 속도\n",
    "drone_speen_x = 10\n",
    "drone_speen_y = 10\n",
    "# 화면 조절\n",
    "set_point_x = 960/2\n",
    "set_point_y = 720/2\n",
    "\n",
    "# 드론 초기화\n",
    "drone = Tello()\n",
    "drone.connect()\n",
    "\n",
    "# 스트림 연결 오류 \n",
    "drone.streamon()\n",
    "\n",
    "# 모델 임포트\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "while True :\n",
    "  # takeoff\n",
    "  if startCounter == 0 :\n",
    "    drone.takeoff()\n",
    "    print('takeoff')\n",
    "    startCounter = 1\n",
    "\n",
    "  # 프레임 읽어오기\n",
    "  frame = drone.get_frame_read().frame\n",
    "  # 읽은 프레임 회색으로 스케일 변환\n",
    "  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # 얼굴 검출\n",
    "  faces = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minSize=(30,30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "  i = 0 \n",
    "\n",
    "  for (x, y, w, h) in faces:\n",
    "    # 인식 표시\n",
    "    cv2.rectangle(frame, (x,y), (x+w, y+h), (0,0,255), 2) # 인식얼굴 표시\n",
    "    cv2.circle(frame, (int(x+w/2) , int(y+h/2)), 12, (255,0,0), 1) # 얼굴 중심 표시\n",
    "\n",
    "    cv2.circle(frame, (int(set_point_x), int(set_point_y)), 12, (255,255,0), 3) # 화면 중간에 원표시\n",
    "    i +=1\n",
    "\n",
    "    #  얼굴중심과 화면중심의 차를 계산\n",
    "    distance_x = x+w/2 - set_point_x\n",
    "    distance_y = y+h/2 - set_point_y\n",
    "\n",
    "    up_down_velocity = 0\n",
    "    right_left_veiocity = 0\n",
    "\n",
    "# 드론 좌우 이동\n",
    "    if distance_x < -tolerance_x:\n",
    "      print(\"left move\")\n",
    "      right_left_veiocity = - drone_speen_x\n",
    "    elif distance_x > tolerance_x:\n",
    "      print(\"right move\")\n",
    "      right_left_veiocity = drone_speen_x\n",
    "    else :\n",
    "      print(\"OK\")\n",
    "\n",
    "  # 드론 상하 이동\n",
    "    if distance_y < -tolerance_y:\n",
    "      print(\"up move\")\n",
    "      up_down_velocity = drone_speen_y\n",
    "    elif distance_y > tolerance_y:\n",
    "      print(\"down move\")\n",
    "      up_down_velocity = - drone_speen_y\n",
    "    else :\n",
    "      print(\"OK\")\n",
    "\n",
    "#  임계치 이상 벗어나면 속도 조정 \n",
    "    if abs(distance_x) < slowdown_threshold_x:\n",
    "      right_left_veiocity = int(right_left_veiocity / 2)\n",
    "    if abs(distance_y) < slowdown_threshold_y:\n",
    "      up_down_velocity = int(up_down_velocity / 2)\n",
    "\n",
    "    # 드론 움직이기\n",
    "    drone.send_rc_control(right_left_veiocity, 0, up_down_velocity, 0)\n",
    "  \n",
    "  cv2.imshow(\"Video\", frame)\n",
    "\n",
    "  key = cv2.waitKey(1)\n",
    "  if key == ord('q'):\n",
    "    break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "drone.streamoff()\n",
    "drone.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 122 - Tello instance was initialized. Host: '192.168.10.1'. Port: '8889'.\n",
      "[INFO] tello.py - 437 - Send command: 'command'\n",
      "[INFO] tello.py - 461 - Response command: 'ok'\n",
      "[INFO] tello.py - 437 - Send command: 'streamon'\n",
      "[INFO] tello.py - 461 - Response streamon: 'ok'\n",
      "[INFO] tello.py - 437 - Send command: 'streamoff'\n",
      "[INFO] tello.py - 461 - Response streamoff: 'ok'\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to grab first frame from video stream",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nono\\Desktop\\Github\\jeju_AI\\haarcascade model.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/haarcascade%20model.ipynb#ch0000003?line=30'>31</a>\u001b[0m   startCounter \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/haarcascade%20model.ipynb#ch0000003?line=32'>33</a>\u001b[0m \u001b[39m# 프레임 읽어오기\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/haarcascade%20model.ipynb#ch0000003?line=33'>34</a>\u001b[0m frame \u001b[39m=\u001b[39m drone\u001b[39m.\u001b[39;49mget_frame_read()\u001b[39m.\u001b[39mframe\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/haarcascade%20model.ipynb#ch0000003?line=35'>36</a>\u001b[0m img_hsv \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(frame, cv2\u001b[39m.\u001b[39mCOLOR_BGR2HSV)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/haarcascade%20model.ipynb#ch0000003?line=37'>38</a>\u001b[0m img_hsv \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mfastNlMeansDenoisingColored(img_hsv,\u001b[39mNone\u001b[39;00m,\u001b[39m10\u001b[39m,\u001b[39m10\u001b[39m,\u001b[39m7\u001b[39m,\u001b[39m21\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nono\\anaconda3\\envs\\test\\lib\\site-packages\\djitellopy\\enforce_types.py:54\u001b[0m, in \u001b[0;36menforce_types.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     53\u001b[0m     check_types(spec, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nono\\anaconda3\\envs\\test\\lib\\site-packages\\djitellopy\\tello.py:420\u001b[0m, in \u001b[0;36mTello.get_frame_read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackground_frame_read \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m     address \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_udp_video_address()\n\u001b[1;32m--> 420\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackground_frame_read \u001b[39m=\u001b[39m BackgroundFrameRead(\u001b[39mself\u001b[39;49m, address)  \u001b[39m# also sets self.cap\u001b[39;00m\n\u001b[0;32m    421\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackground_frame_read\u001b[39m.\u001b[39mstart()\n\u001b[0;32m    422\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackground_frame_read\n",
      "File \u001b[1;32mc:\\Users\\nono\\anaconda3\\envs\\test\\lib\\site-packages\\djitellopy\\tello.py:1048\u001b[0m, in \u001b[0;36mBackgroundFrameRead.__init__\u001b[1;34m(self, tello, address)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.05\u001b[39m)\n\u001b[0;32m   1047\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrabbed \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1048\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mFailed to grab first frame from video stream\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1050\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstopped \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworker \u001b[39m=\u001b[39m Thread(target\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_frame, args\u001b[39m=\u001b[39m(), daemon\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mException\u001b[0m: Failed to grab first frame from video stream"
     ]
    }
   ],
   "source": [
    "# 스타트flag\n",
    "startCounter = 1\n",
    "\n",
    "# 임계값 조절\n",
    "tolerance_x = 3\n",
    "tolerance_y = 3\n",
    "# 속도 한계값\n",
    "slowdown_threshold_x = 15\n",
    "slowdown_threshold_y = 15\n",
    "# 속도\n",
    "drone_speen_x = 10\n",
    "drone_speen_y = 10\n",
    "# 화면 조절\n",
    "set_point_x = 960/2\n",
    "set_point_y = 720/2\n",
    "\n",
    "# 드론 초기화\n",
    "drone = Tello()\n",
    "drone.connect()\n",
    "\n",
    "# 스트림 연결 오류 \n",
    "drone.streamon()\n",
    "\n",
    "# 모델 임포트\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "while True :\n",
    "  frame = drone.get_frame_read().frame\n",
    "  # takeoff\n",
    "  if startCounter == 0 :\n",
    "    drone.takeoff()\n",
    "    print('takeoff')\n",
    "    startCounter = 1\n",
    "\n",
    "  # 프레임 읽어오기\n",
    "  frame = drone.get_frame_read().frame\n",
    "\n",
    "  img_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "  img_hsv = cv2.fastNlMeansDenoisingColored(img_hsv,None,10,10,7,21)\n",
    "  lower = np.array([0,48,80], dtype=\"uint8\")\n",
    "  upper = np.array([20,255,255], dtype=\"uint8\")\n",
    "  img_hand = cv2.inRange(img_hsv,lower,upper)\n",
    "  \n",
    "  #경계선 찾음\n",
    "  contours, hierarchy = cv2.findContours(img_hand, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  # 가장 큰 영역 찾기\n",
    "  max = 0\n",
    "  maxcnt = None\n",
    "  for cnt in contours :\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if(max < area) :\n",
    "      max = area\n",
    "      maxcnt = cnt\n",
    "      if maxcnt.all() == None:\n",
    "        break\n",
    "  #print(maxcnt)\n",
    "  \n",
    "  mask = np.zeros(frame.shape).astype(frame.dtype)\n",
    "  # 경계선 내부 255로 채우기\n",
    "  color = [255, 255, 255]\n",
    "  cv2.fillPoly(mask, [maxcnt], color)\n",
    "  img_hand = cv2.bitwise_and(frame, mask)\n",
    "  hull = cv2.convexHull(maxcnt)\n",
    "\n",
    "  # 도출된 값으로 사각형 그리기\n",
    "  x,y,w,h = cv2.boundingRect(hull)\n",
    "  cv2.rectangle(mask, (x,y), (x+w,y+h), (0,255,0),3 )\n",
    "  cv2.circle(frame, (int(x+w/2) , int(y+h/2)), 12, (255,0,0), 1) # 얼굴 중심 표시\n",
    "\n",
    "\n",
    "  # 읽은 프레임 회색으로 스케일 변환\n",
    "  # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # 얼굴 검출\n",
    "  # faces = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minSize=(30,30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "  # i = 0 \n",
    "\n",
    "#   for (x, y, w, h) in faces:\n",
    "#     # 인식 표시\n",
    "#     cv2.rectangle(frame, (x,y), (x+w, y+h), (0,0,255), 2) # 인식얼굴 표시\n",
    "#     cv2.circle(frame, (int(x+w/2) , int(y+h/2)), 12, (255,0,0), 1) # 얼굴 중심 표시\n",
    "\n",
    "#     cv2.circle(frame, (int(set_point_x), int(set_point_y)), 12, (255,255,0), 3) # 화면 중간에 원표시\n",
    "#     i +=1\n",
    "\n",
    "#     #  얼굴중심과 화면중심의 차를 계산\n",
    "#     distance_x = x+w/2 - set_point_x\n",
    "#     distance_y = y+h/2 - set_point_y\n",
    "\n",
    "#     up_down_velocity = 0\n",
    "#     right_left_veiocity = 0\n",
    "\n",
    "# # 드론 좌우 이동\n",
    "#     if distance_x < -tolerance_x:\n",
    "#       print(\"left move\")\n",
    "#       right_left_veiocity = - drone_speen_x\n",
    "#     elif distance_x > tolerance_x:\n",
    "#       print(\"right move\")\n",
    "#       right_left_veiocity = drone_speen_x\n",
    "#     else :\n",
    "#       print(\"OK\")\n",
    "\n",
    "#   # 드론 상하 이동\n",
    "#     if distance_y < -tolerance_y:\n",
    "#       print(\"up move\")\n",
    "#       up_down_velocity = drone_speen_y\n",
    "#     elif distance_y > tolerance_y:\n",
    "#       print(\"down move\")\n",
    "#       up_down_velocity = - drone_speen_y\n",
    "#     else :\n",
    "#       print(\"OK\")\n",
    "\n",
    "# #  임계치 이상 벗어나면 속도 조정 \n",
    "#     if abs(distance_x) < slowdown_threshold_x:\n",
    "#       right_left_veiocity = int(right_left_veiocity / 2)\n",
    "#     if abs(distance_y) < slowdown_threshold_y:\n",
    "#       up_down_velocity = int(up_down_velocity / 2)\n",
    "\n",
    "    # 드론 움직이기\n",
    "    # drone.send_rc_control(right_left_veiocity, 0, up_down_velocity, 0)\n",
    "\n",
    "\n",
    "  cv2.imshow(\"Video\", frame)\n",
    "\n",
    "  key = cv2.waitKey(1)\n",
    "  if key == ord('q'):\n",
    "    break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "drone.streamoff()\n",
    "drone.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20ae79076fa093aace5f0b55cb31860454b1b79009f440bd24f2599b382fd2c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
