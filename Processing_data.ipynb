{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성 및 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras import applications, models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "def get_data(path):\n",
    "    x = []\n",
    "    y = []\n",
    "    dir_list = os.listdir(path)\n",
    "    for i in range(len(dir_list)-1):\n",
    "        dir_path = path + \"/\" + dir_list[i+1]\n",
    "        dir_name = os.listdir(dir_path)\n",
    "\n",
    "        for j in range(len(dir_name)):\n",
    "            full_dir_path = dir_path + \"/\" + dir_name[j]\n",
    "\n",
    "            img = cv2.imread(full_dir_path)\n",
    "            img = cv2.resize(img, (32,32))\n",
    "            x.append(img)\n",
    "            y.append(i)\n",
    "    # print(x)\n",
    "    # print(y)\n",
    "    return np.array(x),np.array(y)\n",
    "#get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(path):\n",
    "    x = []\n",
    "    y = []\n",
    "    dir_list = os.listdir(path)\n",
    "    #print(os.listdir(path))\n",
    "    for i in range(0,len(dir_list)):\n",
    "        # if i == 1:\n",
    "        #     break\n",
    "        dir_path = path + \"/\" + dir_list[i]\n",
    "        #print(os.listdir(dir_path))\n",
    "        dir_name = os.listdir(dir_path)\n",
    "        \n",
    "        for j in range(len(dir_name)):\n",
    "            \n",
    "            full_dir_path = dir_path + \"/\" + dir_name[j]\n",
    "            print(full_dir_path)\n",
    "            img = cv2.imread(full_dir_path,cv2.IMREAD_COLOR)\n",
    "            \n",
    "            # 색 변경\n",
    "            img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            img_hsv = cv2.fastNlMeansDenoisingColored(img_hsv,None,10,10,7,21)\n",
    "            lower = np.array([0,48,80], dtype=\"uint8\")\n",
    "            upper = np.array([20,255,255], dtype=\"uint8\")\n",
    "            img_hand = cv2.inRange(img_hsv,lower,upper)\n",
    "            \n",
    "\n",
    "            #경계선 찾음\n",
    "            contours, hierarchy = cv2.findContours(img_hand, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            # 가장 큰 영역 찾기\n",
    "            max = 0\n",
    "            maxcnt = None\n",
    "            \n",
    "            \n",
    "            \n",
    "            for cnt in contours :\n",
    "                area = cv2.contourArea(cnt)\n",
    "                if(max < area) :\n",
    "                    max = area\n",
    "                    maxcnt = cnt\n",
    "            #print(\"maxcnt : \",maxcnt)\n",
    "            if maxcnt != np.array([]):\n",
    "                mask = np.zeros(img.shape).astype(img.dtype)\n",
    "                #print(mask)\n",
    "                # 경계선 내부 255로 채우기\n",
    "                color = [255, 255, 255]\n",
    "                cv2.fillPoly(mask, [maxcnt], color)\n",
    "                img_hand = cv2.bitwise_and(img, mask)\n",
    "                \n",
    "                \n",
    "                img_hand = cv2.resize(img_hand, (100,100))\n",
    "                cv2.imwrite('image.png', img_hand)\n",
    "                x.append(img_hand)\n",
    "                y.append(i)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "    #print(x.shape)\n",
    "    #print(y.shape)\n",
    "    return np.array(x),np.array(y)\n",
    "\n",
    "#process_data(\"./data/train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "def make_model() :\n",
    "    resnet50 = applications.resnet50.ResNet50(include_top=False, weights=\"imagenet\", input_shape=(100,100,3))\n",
    "    resnet50.trainable = False\n",
    "    model = models.Sequential()\n",
    "    model.add(resnet50)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1024, activation=\"relu\"))\n",
    "    model.add(layers.Dense(512, activation=\"relu\"))\n",
    "    #model.add(layers.Dense(256, activation=\"relu\"))\n",
    "\n",
    "    # 분류 데이터가 몇종류인지\n",
    "    model.add(layers.Dense(2, activation=\"softmax\"))\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics = [\"accuracy\"])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한개 테스트용\n",
    "def get_test():\n",
    "    test_path = \"./test/non/test17.png\"\n",
    "    test_img = cv2.imread(test_path)\n",
    "    #print(test_img)\n",
    "    test_img = cv2.resize(test_img, (32,32))\n",
    "    #test_img = test_img.reshape(32,32,3)\n",
    "    test_list = []\n",
    "    test_list.append(test_img)\n",
    "    test_list = np.array(test_list)\n",
    "    #print(test_img.shape)\n",
    "    cv2.imwrite(\"test123.png\",test_img)\n",
    "    return test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/train/non/176.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xl/l17__8q55nsdyt859lgd1nvc0000gn/T/ipykernel_50052/95893456.py:43: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if maxcnt != np.array([]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/train/non/162.png\n",
      "./data/train/non/189.png\n",
      "./data/train/non/77.png\n",
      "./data/train/non/63.png\n",
      "./data/train/non/62.png\n",
      "./data/train/non/188.png\n",
      "./data/train/non/76.png\n",
      "./data/train/non/163.png\n",
      "./data/train/non/177.png\n",
      "./data/train/non/89.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xl/l17__8q55nsdyt859lgd1nvc0000gn/T/ipykernel_50052/95893456.py:43: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if maxcnt != np.array([]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/train/non/149.png\n",
      "./data/train/non/161.png\n",
      "./data/train/non/175.png\n",
      "./data/train/non/60.png\n",
      "./data/train/non/74.png\n",
      "./data/train/non/48.png\n",
      "./data/train/non/49.png\n",
      "./data/train/non/75.png\n",
      "./data/train/non/61.png\n",
      "./data/train/non/174.png\n",
      "./data/train/non/160.png\n",
      "./data/train/non/148.png\n",
      "./data/train/non/164.png\n",
      "./data/train/non/170.png\n",
      "./data/train/non/158.png\n",
      "./data/train/non/59.png\n",
      "./data/train/non/65.png\n",
      "./data/train/non/71.png\n",
      "./data/train/non/70.png\n",
      "./data/train/non/64.png\n",
      "./data/train/non/58.png\n",
      "./data/train/non/159.png\n",
      "./data/train/non/171.png\n",
      "./data/train/non/165.png\n",
      "./data/train/non/173.png\n",
      "./data/train/non/167.png\n",
      "./data/train/non/99.png\n",
      "./data/train/non/8.png\n",
      "./data/train/non/72.png\n",
      "./data/train/non/66.png\n",
      "./data/train/non/67.png\n",
      "./data/train/non/73.png\n",
      "./data/train/non/9.png\n",
      "./data/train/non/166.png\n",
      "./data/train/non/98.png\n",
      "./data/train/non/172.png\n",
      "./data/train/non/129.png\n",
      "./data/train/non/115.png\n",
      "./data/train/non/101.png\n",
      "./data/train/non/14.png\n",
      "./data/train/non/28.png\n",
      "./data/train/non/29.png\n",
      "./data/train/non/15.png\n",
      "./data/train/non/100.png\n",
      "./data/train/non/114.png\n",
      "./data/train/non/128.png\n",
      "./data/train/non/102.png\n",
      "./data/train/non/116.png\n",
      "./data/train/non/17.png\n",
      "./data/train/non/16.png\n",
      "./data/train/non/117.png\n",
      "./data/train/non/103.png\n",
      "./data/train/non/107.png\n",
      "./data/train/non/113.png\n",
      "./data/train/non/12.png\n",
      "./data/train/non/13.png\n",
      "./data/train/non/112.png\n",
      "./data/train/non/106.png\n",
      "./data/train/non/110.png\n",
      "./data/train/non/104.png\n",
      "./data/train/non/138.png\n",
      "./data/train/non/39.png\n",
      "./data/train/non/11.png\n",
      "./data/train/non/10.png\n",
      "./data/train/non/38.png\n",
      "./data/train/non/139.png\n",
      "./data/train/non/105.png\n",
      "./data/train/non/111.png\n",
      "./data/train/non/108.png\n",
      "./data/train/non/134.png\n",
      "./data/train/non/120.png\n",
      "./data/train/non/35.png\n",
      "./data/train/non/21.png\n",
      "./data/train/non/20.png\n",
      "./data/train/non/34.png\n",
      "./data/train/non/121.png\n",
      "./data/train/non/135.png\n",
      "./data/train/non/109.png\n",
      "./data/train/non/123.png\n",
      "./data/train/non/137.png\n",
      "./data/train/non/22.png\n",
      "./data/train/non/36.png\n",
      "./data/train/non/37.png\n",
      "./data/train/non/23.png\n",
      "./data/train/non/136.png\n",
      "./data/train/non/122.png\n",
      "./data/train/non/126.png\n",
      "./data/train/non/132.png\n",
      "./data/train/non/27.png\n",
      "./data/train/non/33.png\n",
      "./data/train/non/32.png\n",
      "./data/train/non/26.png\n",
      "./data/train/non/133.png\n",
      "./data/train/non/127.png\n",
      "./data/train/non/131.png\n",
      "./data/train/non/125.png\n",
      "./data/train/non/119.png\n",
      "./data/train/non/18.png\n",
      "./data/train/non/30.png\n",
      "./data/train/non/24.png\n",
      "./data/train/non/25.png\n",
      "./data/train/non/31.png\n",
      "./data/train/non/19.png\n",
      "./data/train/non/118.png\n",
      "./data/train/non/124.png\n",
      "./data/train/non/130.png\n",
      "./data/train/non/95.png\n",
      "./data/train/non/81.png\n",
      "./data/train/non/157.png\n",
      "./data/train/non/143.png\n",
      "./data/train/non/4.png\n",
      "./data/train/non/56.png\n",
      "./data/train/non/42.png\n",
      "./data/train/non/194.png\n",
      "./data/train/non/180.png\n",
      "./data/train/non/181.png\n",
      "./data/train/non/195.png\n",
      "./data/train/non/43.png\n",
      "./data/train/non/5.png\n",
      "./data/train/non/57.png\n",
      "./data/train/non/142.png\n",
      "./data/train/non/156.png\n",
      "./data/train/non/80.png\n",
      "./data/train/non/94.png\n",
      "./data/train/non/82.png\n",
      "./data/train/non/96.png\n",
      "./data/train/non/168.png\n",
      "./data/train/non/140.png\n",
      "./data/train/non/154.png\n",
      "./data/train/non/41.png\n",
      "./data/train/non/55.png\n",
      "./data/train/non/7.png\n",
      "./data/train/non/183.png\n",
      "./data/train/non/69.png\n",
      "./data/train/non/197.png\n",
      "./data/train/non/68.png\n",
      "./data/train/non/196.png\n",
      "./data/train/non/182.png\n",
      "./data/train/non/54.png\n",
      "./data/train/non/6.png\n",
      "./data/train/non/40.png\n",
      "./data/train/non/155.png\n",
      "./data/train/non/141.png\n",
      "./data/train/non/97.png\n",
      "./data/train/non/169.png\n",
      "./data/train/non/83.png\n",
      "./data/train/non/145.png\n",
      "./data/train/non/151.png\n",
      "./data/train/non/87.png\n",
      "./data/train/non/179.png\n",
      "./data/train/non/93.png\n",
      "./data/train/non/78.png\n",
      "./data/train/non/186.png\n",
      "./data/train/non/192.png\n",
      "./data/train/non/44.png\n",
      "./data/train/non/2.png\n",
      "./data/train/non/50.png\n",
      "./data/train/non/3.png\n",
      "./data/train/non/51.png\n",
      "./data/train/non/45.png\n",
      "./data/train/non/193.png\n",
      "./data/train/non/79.png\n",
      "./data/train/non/187.png\n",
      "./data/train/non/92.png\n",
      "./data/train/non/86.png\n",
      "./data/train/non/178.png\n",
      "./data/train/non/150.png\n",
      "./data/train/non/144.png\n",
      "./data/train/non/152.png\n",
      "./data/train/non/146.png\n",
      "./data/train/non/90.png\n",
      "./data/train/non/84.png\n",
      "./data/train/non/191.png\n",
      "./data/train/non/185.png\n",
      "./data/train/non/53.png\n",
      "./data/train/non/1.png\n",
      "./data/train/non/47.png\n",
      "./data/train/non/46.png\n",
      "./data/train/non/52.png\n",
      "./data/train/non/0.png\n",
      "./data/train/non/184.png\n",
      "./data/train/non/190.png\n",
      "./data/train/non/85.png\n",
      "./data/train/non/91.png\n",
      "./data/train/non/147.png\n",
      "./data/train/non/153.png\n",
      "./data/train/seungmin/176.png\n",
      "./data/train/seungmin/88.png\n",
      "./data/train/seungmin/162.png\n",
      "./data/train/seungmin/189.png\n",
      "./data/train/seungmin/77.png\n",
      "./data/train/seungmin/63.png\n",
      "./data/train/seungmin/62.png\n",
      "./data/train/seungmin/188.png\n",
      "./data/train/seungmin/76.png\n",
      "./data/train/seungmin/163.png\n",
      "./data/train/seungmin/177.png\n",
      "./data/train/seungmin/89.png\n",
      "./data/train/seungmin/149.png\n",
      "./data/train/seungmin/161.png\n",
      "./data/train/seungmin/175.png\n",
      "./data/train/seungmin/60.png\n",
      "./data/train/seungmin/74.png\n",
      "./data/train/seungmin/48.png\n",
      "./data/train/seungmin/49.png\n",
      "./data/train/seungmin/75.png\n",
      "./data/train/seungmin/61.png\n",
      "./data/train/seungmin/174.png\n",
      "./data/train/seungmin/160.png\n",
      "./data/train/seungmin/148.png\n",
      "./data/train/seungmin/164.png\n",
      "./data/train/seungmin/170.png\n",
      "./data/train/seungmin/158.png\n",
      "./data/train/seungmin/59.png\n",
      "./data/train/seungmin/65.png\n",
      "./data/train/seungmin/71.png\n",
      "./data/train/seungmin/70.png\n",
      "./data/train/seungmin/64.png\n",
      "./data/train/seungmin/58.png\n",
      "./data/train/seungmin/159.png\n",
      "./data/train/seungmin/171.png\n",
      "./data/train/seungmin/165.png\n",
      "./data/train/seungmin/173.png\n",
      "./data/train/seungmin/167.png\n",
      "./data/train/seungmin/99.png\n",
      "./data/train/seungmin/8.png\n",
      "./data/train/seungmin/72.png\n",
      "./data/train/seungmin/66.png\n",
      "./data/train/seungmin/67.png\n",
      "./data/train/seungmin/73.png\n",
      "./data/train/seungmin/9.png\n",
      "./data/train/seungmin/166.png\n",
      "./data/train/seungmin/98.png\n",
      "./data/train/seungmin/172.png\n",
      "./data/train/seungmin/129.png\n",
      "./data/train/seungmin/115.png\n",
      "./data/train/seungmin/101.png\n",
      "./data/train/seungmin/14.png\n",
      "./data/train/seungmin/28.png\n",
      "./data/train/seungmin/29.png\n",
      "./data/train/seungmin/15.png\n",
      "./data/train/seungmin/100.png\n",
      "./data/train/seungmin/114.png\n",
      "./data/train/seungmin/128.png\n",
      "./data/train/seungmin/102.png\n",
      "./data/train/seungmin/116.png\n",
      "./data/train/seungmin/17.png\n",
      "./data/train/seungmin/16.png\n",
      "./data/train/seungmin/117.png\n",
      "./data/train/seungmin/103.png\n",
      "./data/train/seungmin/107.png\n",
      "./data/train/seungmin/113.png\n",
      "./data/train/seungmin/12.png\n",
      "./data/train/seungmin/13.png\n",
      "./data/train/seungmin/112.png\n",
      "./data/train/seungmin/106.png\n",
      "./data/train/seungmin/110.png\n",
      "./data/train/seungmin/104.png\n",
      "./data/train/seungmin/138.png\n",
      "./data/train/seungmin/39.png\n",
      "./data/train/seungmin/11.png\n",
      "./data/train/seungmin/10.png\n",
      "./data/train/seungmin/38.png\n",
      "./data/train/seungmin/139.png\n",
      "./data/train/seungmin/105.png\n",
      "./data/train/seungmin/111.png\n",
      "./data/train/seungmin/108.png\n",
      "./data/train/seungmin/134.png\n",
      "./data/train/seungmin/120.png\n",
      "./data/train/seungmin/35.png\n",
      "./data/train/seungmin/21.png\n",
      "./data/train/seungmin/20.png\n",
      "./data/train/seungmin/34.png\n",
      "./data/train/seungmin/121.png\n",
      "./data/train/seungmin/135.png\n",
      "./data/train/seungmin/109.png\n",
      "./data/train/seungmin/123.png\n",
      "./data/train/seungmin/137.png\n",
      "./data/train/seungmin/22.png\n",
      "./data/train/seungmin/36.png\n",
      "./data/train/seungmin/37.png\n",
      "./data/train/seungmin/23.png\n",
      "./data/train/seungmin/136.png\n",
      "./data/train/seungmin/122.png\n",
      "./data/train/seungmin/126.png\n",
      "./data/train/seungmin/132.png\n",
      "./data/train/seungmin/27.png\n",
      "./data/train/seungmin/33.png\n",
      "./data/train/seungmin/32.png\n",
      "./data/train/seungmin/26.png\n",
      "./data/train/seungmin/133.png\n",
      "./data/train/seungmin/127.png\n",
      "./data/train/seungmin/131.png\n",
      "./data/train/seungmin/125.png\n",
      "./data/train/seungmin/119.png\n",
      "./data/train/seungmin/18.png\n",
      "./data/train/seungmin/30.png\n",
      "./data/train/seungmin/24.png\n",
      "./data/train/seungmin/25.png\n",
      "./data/train/seungmin/31.png\n",
      "./data/train/seungmin/19.png\n",
      "./data/train/seungmin/118.png\n",
      "./data/train/seungmin/124.png\n",
      "./data/train/seungmin/130.png\n",
      "./data/train/seungmin/95.png\n",
      "./data/train/seungmin/81.png\n",
      "./data/train/seungmin/157.png\n",
      "./data/train/seungmin/143.png\n",
      "./data/train/seungmin/4.png\n",
      "./data/train/seungmin/56.png\n",
      "./data/train/seungmin/42.png\n",
      "./data/train/seungmin/180.png\n",
      "./data/train/seungmin/181.png\n",
      "./data/train/seungmin/43.png\n",
      "./data/train/seungmin/5.png\n",
      "./data/train/seungmin/57.png\n",
      "./data/train/seungmin/142.png\n",
      "./data/train/seungmin/156.png\n",
      "./data/train/seungmin/80.png\n",
      "./data/train/seungmin/94.png\n",
      "./data/train/seungmin/82.png\n",
      "./data/train/seungmin/96.png\n",
      "./data/train/seungmin/168.png\n",
      "./data/train/seungmin/140.png\n",
      "./data/train/seungmin/154.png\n",
      "./data/train/seungmin/41.png\n",
      "./data/train/seungmin/55.png\n",
      "./data/train/seungmin/7.png\n",
      "./data/train/seungmin/183.png\n",
      "./data/train/seungmin/69.png\n",
      "./data/train/seungmin/68.png\n",
      "./data/train/seungmin/182.png\n",
      "./data/train/seungmin/54.png\n",
      "./data/train/seungmin/6.png\n",
      "./data/train/seungmin/40.png\n",
      "./data/train/seungmin/155.png\n",
      "./data/train/seungmin/141.png\n",
      "./data/train/seungmin/97.png\n",
      "./data/train/seungmin/169.png\n",
      "./data/train/seungmin/83.png\n",
      "./data/train/seungmin/145.png\n",
      "./data/train/seungmin/151.png\n",
      "./data/train/seungmin/87.png\n",
      "./data/train/seungmin/179.png\n",
      "./data/train/seungmin/93.png\n",
      "./data/train/seungmin/78.png\n",
      "./data/train/seungmin/186.png\n",
      "./data/train/seungmin/44.png\n",
      "./data/train/seungmin/2.png\n",
      "./data/train/seungmin/50.png\n",
      "./data/train/seungmin/3.png\n",
      "./data/train/seungmin/51.png\n",
      "./data/train/seungmin/45.png\n",
      "./data/train/seungmin/79.png\n",
      "./data/train/seungmin/187.png\n",
      "./data/train/seungmin/92.png\n",
      "./data/train/seungmin/86.png\n",
      "./data/train/seungmin/178.png\n",
      "./data/train/seungmin/150.png\n",
      "./data/train/seungmin/144.png\n",
      "./data/train/seungmin/152.png\n",
      "./data/train/seungmin/146.png\n",
      "./data/train/seungmin/90.png\n",
      "./data/train/seungmin/84.png\n",
      "./data/train/seungmin/191.png\n",
      "./data/train/seungmin/185.png\n",
      "./data/train/seungmin/53.png\n",
      "./data/train/seungmin/1.png\n",
      "./data/train/seungmin/47.png\n",
      "./data/train/seungmin/46.png\n",
      "./data/train/seungmin/52.png\n",
      "./data/train/seungmin/0.png\n",
      "./data/train/seungmin/184.png\n",
      "./data/train/seungmin/190.png\n",
      "./data/train/seungmin/85.png\n",
      "./data/train/seungmin/91.png\n",
      "./data/train/seungmin/147.png\n",
      "./data/train/seungmin/153.png\n",
      "./data/test/non/63.png\n",
      "./data/test/non/62.png\n",
      "./data/test/non/60.png\n",
      "./data/test/non/48.png\n",
      "./data/test/non/49.png\n",
      "./data/test/non/61.png\n",
      "./data/test/non/59.png\n",
      "./data/test/non/65.png\n",
      "./data/test/non/71.png\n",
      "./data/test/non/70.png\n",
      "./data/test/non/64.png\n",
      "./data/test/non/58.png\n",
      "./data/test/non/8.png\n",
      "./data/test/non/72.png\n",
      "./data/test/non/66.png\n",
      "./data/test/non/67.png\n",
      "./data/test/non/9.png\n",
      "./data/test/non/14.png\n",
      "./data/test/non/28.png\n",
      "./data/test/non/29.png\n",
      "./data/test/non/15.png\n",
      "./data/test/non/17.png\n",
      "./data/test/non/16.png\n",
      "./data/test/non/12.png\n",
      "./data/test/non/13.png\n",
      "./data/test/non/39.png\n",
      "./data/test/non/11.png\n",
      "./data/test/non/10.png\n",
      "./data/test/non/38.png\n",
      "./data/test/non/35.png\n",
      "./data/test/non/21.png\n",
      "./data/test/non/20.png\n",
      "./data/test/non/34.png\n",
      "./data/test/non/22.png\n",
      "./data/test/non/36.png\n",
      "./data/test/non/37.png\n",
      "./data/test/non/23.png\n",
      "./data/test/non/27.png\n",
      "./data/test/non/33.png\n",
      "./data/test/non/32.png\n",
      "./data/test/non/26.png\n",
      "./data/test/non/18.png\n",
      "./data/test/non/30.png\n",
      "./data/test/non/24.png\n",
      "./data/test/non/25.png\n",
      "./data/test/non/31.png\n",
      "./data/test/non/19.png\n",
      "./data/test/non/4.png\n",
      "./data/test/non/56.png\n",
      "./data/test/non/42.png\n",
      "./data/test/non/43.png\n",
      "./data/test/non/5.png\n",
      "./data/test/non/57.png\n",
      "./data/test/non/41.png\n",
      "./data/test/non/55.png\n",
      "./data/test/non/7.png\n",
      "./data/test/non/69.png\n",
      "./data/test/non/68.png\n",
      "./data/test/non/54.png\n",
      "./data/test/non/6.png\n",
      "./data/test/non/40.png\n",
      "./data/test/non/44.png\n",
      "./data/test/non/2.png\n",
      "./data/test/non/50.png\n",
      "./data/test/non/3.png\n",
      "./data/test/non/51.png\n",
      "./data/test/non/45.png\n",
      "./data/test/non/53.png\n",
      "./data/test/non/1.png\n",
      "./data/test/non/47.png\n",
      "./data/test/non/46.png\n",
      "./data/test/non/52.png\n",
      "./data/test/non/0.png\n",
      "./data/test/seungmin/48.png\n",
      "./data/test/seungmin/49.png\n",
      "./data/test/seungmin/8.png\n",
      "./data/test/seungmin/9.png\n",
      "./data/test/seungmin/14.png\n",
      "./data/test/seungmin/28.png\n",
      "./data/test/seungmin/29.png\n",
      "./data/test/seungmin/15.png\n",
      "./data/test/seungmin/17.png\n",
      "./data/test/seungmin/16.png\n",
      "./data/test/seungmin/12.png\n",
      "./data/test/seungmin/13.png\n",
      "./data/test/seungmin/39.png\n",
      "./data/test/seungmin/11.png\n",
      "./data/test/seungmin/10.png\n",
      "./data/test/seungmin/38.png\n",
      "./data/test/seungmin/35.png\n",
      "./data/test/seungmin/21.png\n",
      "./data/test/seungmin/20.png\n",
      "./data/test/seungmin/34.png\n",
      "./data/test/seungmin/22.png\n",
      "./data/test/seungmin/36.png\n",
      "./data/test/seungmin/37.png\n",
      "./data/test/seungmin/23.png\n",
      "./data/test/seungmin/27.png\n",
      "./data/test/seungmin/33.png\n",
      "./data/test/seungmin/32.png\n",
      "./data/test/seungmin/26.png\n",
      "./data/test/seungmin/18.png\n",
      "./data/test/seungmin/30.png\n",
      "./data/test/seungmin/24.png\n",
      "./data/test/seungmin/25.png\n",
      "./data/test/seungmin/31.png\n",
      "./data/test/seungmin/19.png\n",
      "./data/test/seungmin/4.png\n",
      "./data/test/seungmin/42.png\n",
      "./data/test/seungmin/43.png\n",
      "./data/test/seungmin/5.png\n",
      "./data/test/seungmin/41.png\n",
      "./data/test/seungmin/7.png\n",
      "./data/test/seungmin/6.png\n",
      "./data/test/seungmin/40.png\n",
      "./data/test/seungmin/44.png\n",
      "./data/test/seungmin/2.png\n",
      "./data/test/seungmin/50.png\n",
      "./data/test/seungmin/3.png\n",
      "./data/test/seungmin/51.png\n",
      "./data/test/seungmin/45.png\n",
      "./data/test/seungmin/53.png\n",
      "./data/test/seungmin/1.png\n",
      "./data/test/seungmin/47.png\n",
      "./data/test/seungmin/46.png\n",
      "./data/test/seungmin/52.png\n",
      "./data/test/seungmin/0.png\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 1024)              33555456  \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,668,994\n",
      "Trainable params: 34,081,282\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 21:39:38.660665: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 7s 127ms/step - loss: 4.4286 - accuracy: 0.8966\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 104ms/step - loss: 3.4087 - accuracy: 0.9576\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5454 - accuracy: 0.9708\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 2s 95ms/step - loss: 0.5587 - accuracy: 0.9841\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 2s 93ms/step - loss: 0.0917 - accuracy: 0.9894\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.0906 - accuracy: 0.9920\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 2s 93ms/step - loss: 3.3815e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 2s 95ms/step - loss: 2.4609e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 2s 93ms/step - loss: 7.6032e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 21:40:03.912301: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 390ms/step - loss: 83.9067 - accuracy: 0.5591\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "def learning() :\n",
    "    train_path = \"./data_image\"\n",
    "    test_path = \"./test\"\n",
    "    (x_train, y_train)= process_data(train_path)\n",
    "    (x_test, y_test) = process_data(test_path)\n",
    "    model = make_model()\n",
    "    # print(\"x_train : \",x_train[0])\n",
    "    # print(\"x_train.shape : \",x_train[0].shape)\n",
    "    log = model.fit(x_train, y_train, epochs=2, batch_size=16)\n",
    "    #model.save(\"face.h5\")\n",
    "    \n",
    "    model.evaluate(x_test,y_test)\n",
    "learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "path = \"./tracking/test1.png\"\n",
    "\n",
    "img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "\n",
    "# 색 변경\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "img_hand = cv2.inRange(img_gray,(10), (165))\n",
    "mask = np.zeros(img.shape).astype(img.dtype)\n",
    "\n",
    "#경계선 찾음\n",
    "contours, hierarchy = cv2.findContours(img_hand, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# 가장 큰 영역 찾기\n",
    "max = 0\n",
    "maxcnt = None\n",
    "for cnt in contours :\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if(max < area) :\n",
    "        max = area\n",
    "        maxcnt = cnt\n",
    "\n",
    "\n",
    "# 경계선 내부 255로 채우기\n",
    "color = [255, 255, 255]\n",
    "cv2.fillPoly(mask, [maxcnt], color)\n",
    "img_hand = cv2.bitwise_and(img, mask)\n",
    "hull = cv2.convexHull(maxcnt)\n",
    "#print(hull)\n",
    "\n",
    "# 도출된 값으로 사각형 그리기\n",
    "x,y,w,h = cv2.boundingRect(hull)\n",
    "cv2.rectangle(mask, (x,y), (x+w,y+h), (0,255,0),3 )\n",
    "\n",
    "\n",
    "cv2.imshow('image', mask)\n",
    "#cv2.imshow('image', mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 드론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from djitellopy import Tello\n",
    "\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tello' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nono\\Desktop\\Github\\jeju_AI\\Processing_data.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/Processing_data.ipynb#ch0000001?line=8'>9</a>\u001b[0m   drone\u001b[39m.\u001b[39mend()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/Processing_data.ipynb#ch0000001?line=9'>10</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m power\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/Processing_data.ipynb#ch0000001?line=10'>11</a>\u001b[0m battery_check()\n",
      "\u001b[1;32mc:\\Users\\nono\\Desktop\\Github\\jeju_AI\\Processing_data.ipynb Cell 2'\u001b[0m in \u001b[0;36mbattery_check\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/Processing_data.ipynb#ch0000001?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbattery_check\u001b[39m() : \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/Processing_data.ipynb#ch0000001?line=2'>3</a>\u001b[0m   drone \u001b[39m=\u001b[39m Tello()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/Processing_data.ipynb#ch0000001?line=3'>4</a>\u001b[0m   drone\u001b[39m.\u001b[39mconnect()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nono/Desktop/Github/jeju_AI/Processing_data.ipynb#ch0000001?line=5'>6</a>\u001b[0m   power \u001b[39m=\u001b[39m drone\u001b[39m.\u001b[39mget_battery()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Tello' is not defined"
     ]
    }
   ],
   "source": [
    "# 배터리 체크\n",
    "def battery_check() : \n",
    "  drone = Tello()\n",
    "  drone.connect()\n",
    "\n",
    "  power = drone.get_battery()\n",
    "  if power < 30 : print(\"배터리 부족\", power)q\n",
    "  else : print(\"배터리\", power)\n",
    "  drone.end()\n",
    "  return power\n",
    "battery_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 122 - Tello instance was initialized. Host: '192.168.10.1'. Port: '8889'.\n",
      "[INFO] tello.py - 437 - Send command: 'command'\n",
      "[INFO] tello.py - 461 - Response command: 'ok'\n",
      "[INFO] tello.py - 437 - Send command: 'streamon'\n",
      "[INFO] tello.py - 461 - Response streamon: 'ok'\n",
      "[INFO] tello.py - 437 - Send command: 'takeoff'\n",
      "[WARNING] tello.py - 447 - Aborting command 'takeoff'. Did not receive a response after 20 seconds\n",
      "[INFO] tello.py - 437 - Send command: 'takeoff'\n"
     ]
    }
   ],
   "source": [
    "#  -- 초기값 설정 --\n",
    "# 스타트flag\n",
    "start_counter = 0\n",
    "# 프레임 flag - 이때 딥러닝 예측도 실행해야됨\n",
    "frame_flag = 70\n",
    "# 임계값 조절\n",
    "tolerance_x = 5\n",
    "tolerance_y = 5\n",
    "# 속도 한계값\n",
    "slowdown_threshold_x = 15\n",
    "slowdown_threshold_y = 15\n",
    "# 속도\n",
    "drone_speen_x = 10\n",
    "drone_speen_y = 10\n",
    "# 화면 조절\n",
    "set_point_x = 960/2\n",
    "set_point_y = 720/2\n",
    "hull = 0\n",
    "# x,y,w,h 전역변수\n",
    "# global x, y, w, h\n",
    "x =0\n",
    "y =0\n",
    "w =0\n",
    "h =0\n",
    "accuracy_num = ''\n",
    "\n",
    "# 드론 초기화\n",
    "drone = Tello()\n",
    "drone.connect()\n",
    "\n",
    "# # 스트림 연결 오류 \n",
    "drone.streamon()\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH,1200)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT,1600)\n",
    "# 모델 임포트\n",
    "# faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "model = models.load_model(\"last_model.h5\")\n",
    "#x,y,w,h = 0\n",
    "# ------------ 영상 루프 시작 ------------\n",
    "while True :\n",
    "  # takeoff 설정\n",
    "  if start_counter == 0 :\n",
    "    drone.takeoff()\n",
    "    print('takeoff')\n",
    "    start_counter = 1\n",
    "\n",
    "  # 프레임 읽어오기\n",
    "  frame = drone.get_frame_read().frame\n",
    "  # _, frame = cap.read()\n",
    "\n",
    "  cv2.circle(frame, (int(set_point_x), int(set_point_y)), 12, (255,0,0), 1) # 화면 중간에 원표시\n",
    "  cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3 )\n",
    "  # cv2.putText(frame,f'accuracy = ',accuracy_num,(x+5,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 0.5, cv2.LINE_AA)\n",
    "  # flalg 설정\n",
    "  frame_flag -=1\n",
    "  if frame_flag < 0:\n",
    "    frame_flag =70\n",
    "  #print(frame_flag)\n",
    "  # print(\"frame_flag\", frame_flag)\n",
    "  if frame_flag == 0 :\n",
    "    # ------------ 데이터 가공 ------------\n",
    "    img_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    img_hsv = cv2.fastNlMeansDenoisingColored(img_hsv,None,10,10,7,21)\n",
    "    lower = np.array([0,48,80], dtype=\"uint8\")\n",
    "    upper = np.array([20,255,255], dtype=\"uint8\")\n",
    "    img_hand = cv2.inRange(img_hsv,lower,upper)\n",
    "    \n",
    "    #경계선 찾음\n",
    "    contours, _ = cv2.findContours(img_hand, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # 가장 큰 영역 찾기\n",
    "    max = 0\n",
    "    maxcnt = None\n",
    "    \n",
    "    # 채워주기\n",
    "    for cnt in contours :\n",
    "      area = cv2.contourArea(cnt)\n",
    "      if(max < area) :\n",
    "        max = area\n",
    "        maxcnt = cnt\n",
    "    \n",
    "    # 예외처리\n",
    "    if maxcnt != np.array([]):\n",
    "      mask = np.zeros(frame.shape).astype(frame.dtype)\n",
    "      # 경계선 내부 255로 채우기\n",
    "      color = [255, 255, 255]\n",
    "      cv2.fillPoly(mask, [maxcnt], color)\n",
    "      hull = cv2.convexHull(maxcnt)\n",
    "      x, y, w, h = cv2.boundingRect(hull)\n",
    "      print(\"x,y,w,h : \", x,y,w,h)\n",
    "      cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3 )\n",
    "      cv2.circle(frame, (int(x+w/2) , int(y+h/2)), 12, (0,255,0), 1) # 얼굴 중심 표시\n",
    "      img_hand = cv2.bitwise_and(frame, mask)\n",
    "\n",
    "      #print(\"전\",img_hand.shape)\n",
    "      img_hand = cv2.resize(img_hand, (100,100))\n",
    "      #print(img_hand.shape)\n",
    "    else :\n",
    "      continue\n",
    "    # ------------ 예측 실행 ------------\n",
    "    img_hand = np.array([img_hand])\n",
    "    pred = model.predict(img_hand)\n",
    "    print(\"예측 값 ==>  \",pred)\n",
    "    # accuracy_num = str(pred[0][1])\n",
    "    print(accuracy_num)\n",
    "    pred = np.argmax(pred)\n",
    "    print(\"1 : 얼굴 인식,  0 : 인식 실패 ==> \",pred)\n",
    "    \n",
    "    if pred == 1 :\n",
    "      \n",
    "      frame_flag = 100\n",
    "\n",
    "      # 도출된 값으로 사각형 그리기\n",
    "      \n",
    "\n",
    "      # ------------ 드론 제어 ------------\n",
    "      #  얼굴중심과 화면중심의 차를 계산\n",
    "      distance_x = x+w/2 - set_point_x\n",
    "      distance_y = y+h/2 - set_point_y\n",
    "\n",
    "      up_down_velocity = 0\n",
    "      right_left_veiocity = 0\n",
    "      for_back_veiocity = 0\n",
    "\n",
    "    # 드론 좌우 이동\n",
    "      if distance_x < -tolerance_x:\n",
    "        print(\"left move\")\n",
    "        right_left_veiocity = - drone_speen_x\n",
    "      elif distance_x > tolerance_x:\n",
    "        print(\"right move\")\n",
    "        right_left_veiocity = drone_speen_x\n",
    "      else :\n",
    "        print(\"OK\")\n",
    "\n",
    "      # 드론 상하 이동\n",
    "      if distance_y < -tolerance_y:\n",
    "        print(\"up move\")\n",
    "        up_down_velocity = drone_speen_y\n",
    "      elif distance_y > tolerance_y:\n",
    "        print(\"down move\")\n",
    "        up_down_velocity = - drone_speen_y\n",
    "      else :\n",
    "        print(\"OK\")\n",
    "\n",
    "      # 드론 앞뒤 이동 및 프레임 크면 넘기기\n",
    "      if w*h < 960*720/2:\n",
    "        for_back_veiocity = 10\n",
    "      elif w*h > 960*720/2:\n",
    "        for_back_veiocity = -10\n",
    "      elif w*h > 960*720 :\n",
    "        for_back_veiocity = 10\n",
    "      elif w*h >= 950*700 :\n",
    "        continue\n",
    "      else:\n",
    "        print(\"OK\")\n",
    "\n",
    "      #  임계치 이상 벗어나면 속도 조정 \n",
    "      if abs(distance_x) < slowdown_threshold_x:\n",
    "        right_left_veiocity = int(right_left_veiocity / 2)\n",
    "      if abs(distance_y) < slowdown_threshold_y:\n",
    "        up_down_velocity = int(up_down_velocity / 2)\n",
    "\n",
    "      #드론 움직이기\n",
    "      drone.send_rc_control(right_left_veiocity, 0, up_down_velocity, 0)\n",
    "    else :\n",
    "      # drone.move_left(20)\n",
    "      print(\"0일때 물체 추적\")\n",
    "      continue\n",
    "\n",
    "  # 비디오 띄우기\n",
    "  cv2.imshow(\"Video\", frame)\n",
    "  # 키 설정\n",
    "  key = cv2.waitKey(1)\n",
    "  if key == ord('q'):\n",
    "    break\n",
    "\n",
    "\n",
    "drone.streamoff()\n",
    "cv2.destroyAllWindows()\n",
    "drone.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20ae79076fa093aace5f0b55cb31860454b1b79009f440bd24f2599b382fd2c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
