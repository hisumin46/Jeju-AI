{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras import applications, models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "def get_data(path):\n",
    "    x = []\n",
    "    y = []\n",
    "    dir_list = os.listdir(path)\n",
    "    for i in range(len(dir_list)-1):\n",
    "        dir_path = path + \"/\" + dir_list[i+1]\n",
    "        dir_name = os.listdir(dir_path)\n",
    "\n",
    "        for j in range(len(dir_name)):\n",
    "            full_dir_path = dir_path + \"/\" + dir_name[j]\n",
    "\n",
    "            img = cv2.imread(full_dir_path)\n",
    "            img = cv2.resize(img, (32,32))\n",
    "            x.append(img)\n",
    "            y.append(i)\n",
    "    # print(x)\n",
    "    # print(y)\n",
    "    return np.array(x),np.array(y)\n",
    "#get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "def make_model() :\n",
    "    resnet50 = applications.resnet50.ResNet50(include_top=False, weights=\"imagenet\", input_shape=(700,500,3))\n",
    "    resnet50.trainable = False\n",
    "    model = models.Sequential()\n",
    "    model.add(resnet50)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1024, activation=\"relu\"))\n",
    "    model.add(layers.Dense(512, activation=\"relu\"))\n",
    "\n",
    "    # 분류 데이터가 몇종류인지\n",
    "    model.add(layers.Dense(2, activation=\"softmax\"))\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics = [\"accuracy\"])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한개 테스트용\n",
    "def get_test():\n",
    "    test_path = \"./test/non/test17.png\"\n",
    "    test_img = cv2.imread(test_path)\n",
    "    #print(test_img)\n",
    "    test_img = cv2.resize(test_img, (32,32))\n",
    "    #test_img = test_img.reshape(32,32,3)\n",
    "    test_list = []\n",
    "    test_list.append(test_img)\n",
    "    test_list = np.array(test_list)\n",
    "    #print(test_img.shape)\n",
    "    cv2.imwrite(\"test123.png\",test_img)\n",
    "    return test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_image/non/1019.png\n",
      "./data_image/non/1031.png\n",
      "./data_image/non/1025.png\n",
      "./data_image/non/1024.png\n",
      "./data_image/non/1030.png\n",
      "./data_image/non/1018.png\n",
      "./data_image/non/1026.png\n",
      "./data_image/non/1032.png\n",
      "./data_image/non/1033.png\n",
      "./data_image/non/1027.png\n",
      "./data_image/non/1023.png\n",
      "./data_image/non/1037.png\n",
      "./data_image/non/1036.png\n",
      "./data_image/non/1022.png\n",
      "./data_image/non/1034.png\n",
      "./data_image/non/1020.png\n",
      "./data_image/non/1008.png\n",
      "./data_image/non/1009.png\n",
      "./data_image/non/1021.png\n",
      "./data_image/non/1035.png\n",
      "./data_image/non/1091.png\n",
      "./data_image/non/1085.png\n",
      "./data_image/non/1052.png\n",
      "./data_image/non/1046.png\n",
      "./data_image/non/1047.png\n",
      "./data_image/non/1053.png\n",
      "./data_image/non/1084.png\n",
      "./data_image/non/1090.png\n",
      "./data_image/non/1086.png\n",
      "./data_image/non/1092.png\n",
      "./data_image/non/1079.png\n",
      "./data_image/non/1045.png\n",
      "./data_image/non/1051.png\n",
      "./data_image/non/1050.png\n",
      "./data_image/non/1044.png\n",
      "./data_image/non/1078.png\n",
      "./data_image/non/1093.png\n",
      "./data_image/non/1087.png\n",
      "./data_image/non/1083.png\n",
      "./data_image/non/1097.png\n",
      "./data_image/non/1040.png\n",
      "./data_image/non/1054.png\n",
      "./data_image/non/1068.png\n",
      "./data_image/non/1069.png\n",
      "./data_image/non/1055.png\n",
      "./data_image/non/1041.png\n",
      "./data_image/non/1096.png\n",
      "./data_image/non/1082.png\n",
      "./data_image/non/1094.png\n",
      "./data_image/non/1080.png\n",
      "./data_image/non/1057.png\n",
      "./data_image/non/1043.png\n",
      "./data_image/non/1042.png\n",
      "./data_image/non/1056.png\n",
      "./data_image/non/1081.png\n",
      "./data_image/non/1095.png\n",
      "./data_image/non/1098.png\n",
      "./data_image/non/1073.png\n",
      "./data_image/non/1067.png\n",
      "./data_image/non/1066.png\n",
      "./data_image/non/1072.png\n",
      "./data_image/non/1099.png\n",
      "./data_image/non/1058.png\n",
      "./data_image/non/1064.png\n",
      "./data_image/non/1070.png\n",
      "./data_image/non/1071.png\n",
      "./data_image/non/1065.png\n",
      "./data_image/non/1059.png\n",
      "./data_image/non/1061.png\n",
      "./data_image/non/1075.png\n",
      "./data_image/non/1049.png\n",
      "./data_image/non/1048.png\n",
      "./data_image/non/1074.png\n",
      "./data_image/non/1060.png\n",
      "./data_image/non/1100.png\n",
      "./data_image/non/1089.png\n",
      "./data_image/non/1076.png\n",
      "./data_image/non/1062.png\n",
      "./data_image/non/1063.png\n",
      "./data_image/non/1077.png\n",
      "./data_image/non/1088.png\n",
      "./data_image/non/1038.png\n",
      "./data_image/non/1010.png\n",
      "./data_image/non/1004.png\n",
      "./data_image/non/1005.png\n",
      "./data_image/non/1011.png\n",
      "./data_image/non/1039.png\n",
      "./data_image/non/1007.png\n",
      "./data_image/non/1013.png\n",
      "./data_image/non/1012.png\n",
      "./data_image/non/1006.png\n",
      "./data_image/non/1002.png\n",
      "./data_image/non/1016.png\n",
      "./data_image/non/1017.png\n",
      "./data_image/non/1003.png\n",
      "./data_image/non/1015.png\n",
      "./data_image/non/1001.png\n",
      "./data_image/non/1029.png\n",
      "./data_image/non/1028.png\n",
      "./data_image/non/1000.png\n",
      "./data_image/non/1014.png\n",
      "./data_image/seungmin/837.png\n",
      "./data_image/seungmin/823.png\n",
      "./data_image/seungmin/822.png\n",
      "./data_image/seungmin/836.png\n",
      "./data_image/seungmin/820.png\n",
      "./data_image/seungmin/834.png\n",
      "./data_image/seungmin/808.png\n",
      "./data_image/seungmin/809.png\n",
      "./data_image/seungmin/835.png\n",
      "./data_image/seungmin/821.png\n",
      "./data_image/seungmin/819.png\n",
      "./data_image/seungmin/825.png\n",
      "./data_image/seungmin/831.png\n",
      "./data_image/seungmin/830.png\n",
      "./data_image/seungmin/824.png\n",
      "./data_image/seungmin/818.png\n",
      "./data_image/seungmin/832.png\n",
      "./data_image/seungmin/826.png\n",
      "./data_image/seungmin/827.png\n",
      "./data_image/seungmin/833.png\n",
      "./data_image/seungmin/897.png\n",
      "./data_image/seungmin/883.png\n",
      "./data_image/seungmin/854.png\n",
      "./data_image/seungmin/840.png\n",
      "./data_image/seungmin/868.png\n",
      "./data_image/seungmin/869.png\n",
      "./data_image/seungmin/841.png\n",
      "./data_image/seungmin/855.png\n",
      "./data_image/seungmin/882.png\n",
      "./data_image/seungmin/896.png\n",
      "./data_image/seungmin/880.png\n",
      "./data_image/seungmin/894.png\n",
      "./data_image/seungmin/843.png\n",
      "./data_image/seungmin/857.png\n",
      "./data_image/seungmin/856.png\n",
      "./data_image/seungmin/842.png\n",
      "./data_image/seungmin/895.png\n",
      "./data_image/seungmin/881.png\n",
      "./data_image/seungmin/885.png\n",
      "./data_image/seungmin/891.png\n",
      "./data_image/seungmin/846.png\n",
      "./data_image/seungmin/852.png\n",
      "./data_image/seungmin/853.png\n",
      "./data_image/seungmin/847.png\n",
      "./data_image/seungmin/890.png\n",
      "./data_image/seungmin/884.png\n",
      "./data_image/seungmin/892.png\n",
      "./data_image/seungmin/886.png\n",
      "./data_image/seungmin/879.png\n",
      "./data_image/seungmin/851.png\n",
      "./data_image/seungmin/845.png\n",
      "./data_image/seungmin/844.png\n",
      "./data_image/seungmin/850.png\n",
      "./data_image/seungmin/878.png\n",
      "./data_image/seungmin/887.png\n",
      "./data_image/seungmin/893.png\n",
      "./data_image/seungmin/875.png\n",
      "./data_image/seungmin/861.png\n",
      "./data_image/seungmin/849.png\n",
      "./data_image/seungmin/900.png\n",
      "./data_image/seungmin/848.png\n",
      "./data_image/seungmin/860.png\n",
      "./data_image/seungmin/874.png\n",
      "./data_image/seungmin/889.png\n",
      "./data_image/seungmin/862.png\n",
      "./data_image/seungmin/876.png\n",
      "./data_image/seungmin/877.png\n",
      "./data_image/seungmin/863.png\n",
      "./data_image/seungmin/888.png\n",
      "./data_image/seungmin/898.png\n",
      "./data_image/seungmin/867.png\n",
      "./data_image/seungmin/873.png\n",
      "./data_image/seungmin/872.png\n",
      "./data_image/seungmin/866.png\n",
      "./data_image/seungmin/899.png\n",
      "./data_image/seungmin/858.png\n",
      "./data_image/seungmin/870.png\n",
      "./data_image/seungmin/864.png\n",
      "./data_image/seungmin/865.png\n",
      "./data_image/seungmin/871.png\n",
      "./data_image/seungmin/859.png\n",
      "./data_image/seungmin/816.png\n",
      "./data_image/seungmin/802.png\n",
      "./data_image/seungmin/803.png\n",
      "./data_image/seungmin/817.png\n",
      "./data_image/seungmin/801.png\n",
      "./data_image/seungmin/815.png\n",
      "./data_image/seungmin/829.png\n",
      "./data_image/seungmin/828.png\n",
      "./data_image/seungmin/814.png\n",
      "./data_image/seungmin/800.png\n",
      "./data_image/seungmin/838.png\n",
      "./data_image/seungmin/804.png\n",
      "./data_image/seungmin/810.png\n",
      "./data_image/seungmin/811.png\n",
      "./data_image/seungmin/805.png\n",
      "./data_image/seungmin/839.png\n",
      "./data_image/seungmin/813.png\n",
      "./data_image/seungmin/807.png\n",
      "./data_image/seungmin/806.png\n",
      "./data_image/seungmin/812.png\n",
      "./test/non/980.png\n",
      "./test/non/994.png\n",
      "./test/non/981.png\n",
      "./test/non/997.png\n",
      "./test/non/983.png\n",
      "./test/non/982.png\n",
      "./test/non/996.png\n",
      "./test/non/992.png\n",
      "./test/non/986.png\n",
      "./test/non/979.png\n",
      "./test/non/978.png\n",
      "./test/non/987.png\n",
      "./test/non/993.png\n",
      "./test/non/985.png\n",
      "./test/non/991.png\n",
      "./test/non/990.png\n",
      "./test/non/984.png\n",
      "./test/non/989.png\n",
      "./test/non/976.png\n",
      "./test/non/977.png\n",
      "./test/non/988.png\n",
      "./test/non/975.png\n",
      "./test/non/974.png\n",
      "./test/non/971.png\n",
      "./test/non/998.png\n",
      "./test/non/973.png\n",
      "./test/non/972.png\n",
      "./test/non/999.png\n",
      "./test/seungmin/691 2.png\n",
      "./test/seungmin/675 2.png\n",
      "./test/seungmin/688 2.png\n",
      "./test/seungmin/677 2.png\n",
      "./test/seungmin/693 2.png\n",
      "./test/seungmin/697 2.png\n",
      "./test/seungmin/673 2.png\n",
      "./test/seungmin/671 2.png\n",
      "./test/seungmin/695 2.png\n",
      "./test/seungmin/676 2.png\n",
      "./test/seungmin/692 2.png\n",
      "./test/seungmin/690 2.png\n",
      "./test/seungmin/674 2.png\n",
      "./test/seungmin/689 2.png\n",
      "./test/seungmin/670 2.png\n",
      "./test/seungmin/694 2.png\n",
      "./test/seungmin/696 2.png\n",
      "./test/seungmin/672 2.png\n",
      "./test/seungmin/683 2.png\n",
      "./test/seungmin/698 2.png\n",
      "./test/seungmin/681 2.png\n",
      "./test/seungmin/678 2.png\n",
      "./test/seungmin/685 2.png\n",
      "./test/seungmin/687 2.png\n",
      "./test/seungmin/699 2.png\n",
      "./test/seungmin/680 2.png\n",
      "./test/seungmin/682 2.png\n",
      "./test/seungmin/686 2.png\n",
      "./test/seungmin/679 2.png\n",
      "./test/seungmin/684 2.png\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 22, 16, 2048)      23587712  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 720896)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              738198528 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 762,312,066\n",
      "Trainable params: 738,724,354\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/hongseongmin/miniforge3/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/hongseongmin/miniforge3/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/hongseongmin/miniforge3/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/hongseongmin/miniforge3/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/hongseongmin/miniforge3/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/hongseongmin/miniforge3/envs/py39/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 700, 500, 3), found shape=(None, 500, 700, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000004?line=10'>11</a>\u001b[0m     \u001b[39m#model.save(\"face.h5\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000004?line=12'>13</a>\u001b[0m     model\u001b[39m.\u001b[39mevaluate(x_test,y_test)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000004?line=13'>14</a>\u001b[0m learning()\n",
      "\u001b[1;32m/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb Cell 5'\u001b[0m in \u001b[0;36mlearning\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000004?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m make_model()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000004?line=7'>8</a>\u001b[0m \u001b[39m# print(\"x_train : \",x_train[0])\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000004?line=8'>9</a>\u001b[0m \u001b[39m# print(\"x_train.shape : \",x_train[0].shape)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000004?line=9'>10</a>\u001b[0m log \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000004?line=10'>11</a>\u001b[0m \u001b[39m#model.save(\"face.h5\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000004?line=12'>13</a>\u001b[0m model\u001b[39m.\u001b[39mevaluate(x_test,y_test)\n",
      "File \u001b[0;32m~/miniforge3/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/xl/l17__8q55nsdyt859lgd1nvc0000gn/T/__autograph_generated_fileawpij42h.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/hongseongmin/miniforge3/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/hongseongmin/miniforge3/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/hongseongmin/miniforge3/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/hongseongmin/miniforge3/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/hongseongmin/miniforge3/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/hongseongmin/miniforge3/envs/py39/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 700, 500, 3), found shape=(None, 500, 700, 3)\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "def learning() :\n",
    "    train_path = \"./data_image\"\n",
    "    test_path = \"./test\"\n",
    "    (x_train, y_train)= process_data(train_path)\n",
    "    (x_test, y_test) = process_data(test_path)\n",
    "    model = make_model()\n",
    "    # print(\"x_train : \",x_train[0])\n",
    "    # print(\"x_train.shape : \",x_train[0].shape)\n",
    "    log = model.fit(x_train, y_train, epochs=2, batch_size=16)\n",
    "    #model.save(\"face.h5\")\n",
    "    \n",
    "    model.evaluate(x_test,y_test)\n",
    "learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "path = \"./tracking/test1.png\"\n",
    "\n",
    "img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "\n",
    "# 색 변경\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "img_hand = cv2.inRange(img_gray,(10), (165))\n",
    "mask = np.zeros(img.shape).astype(img.dtype)\n",
    "\n",
    "#경계선 찾음\n",
    "contours, hierarchy = cv2.findContours(img_hand, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# 가장 큰 영역 찾기\n",
    "max = 0\n",
    "maxcnt = None\n",
    "for cnt in contours :\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if(max < area) :\n",
    "        max = area\n",
    "        maxcnt = cnt\n",
    "\n",
    "\n",
    "# 경계선 내부 255로 채우기\n",
    "color = [255, 255, 255]\n",
    "cv2.fillPoly(mask, [maxcnt], color)\n",
    "img_hand = cv2.bitwise_and(img, mask)\n",
    "hull = cv2.convexHull(maxcnt)\n",
    "#print(hull)\n",
    "\n",
    "# 도출된 값으로 사각형 그리기\n",
    "x,y,w,h = cv2.boundingRect(hull)\n",
    "cv2.rectangle(mask, (x,y), (x+w,y+h), (0,255,0),3 )\n",
    "\n",
    "\n",
    "cv2.imshow('image', mask)\n",
    "#cv2.imshow('image', mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_image/non/1019.png\n",
      "./data_image/non/1031.png\n",
      "./data_image/non/1025.png\n",
      "./data_image/non/1024.png\n",
      "./data_image/non/1030.png\n",
      "./data_image/non/1018.png\n",
      "./data_image/non/1026.png\n",
      "./data_image/non/1032.png\n",
      "./data_image/non/1033.png\n",
      "./data_image/non/1027.png\n",
      "./data_image/non/1023.png\n",
      "./data_image/non/1037.png\n",
      "./data_image/non/1036.png\n",
      "./data_image/non/1022.png\n",
      "./data_image/non/1034.png\n",
      "./data_image/non/1020.png\n",
      "./data_image/non/1008.png\n",
      "./data_image/non/1009.png\n",
      "./data_image/non/1021.png\n",
      "./data_image/non/1035.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000006?line=52'>53</a>\u001b[0m     \u001b[39mprint\u001b[39m(y\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000006?line=53'>54</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(x),np\u001b[39m.\u001b[39marray(y)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000006?line=55'>56</a>\u001b[0m process_data(\u001b[39m\"\u001b[39;49m\u001b[39m./data_image\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb Cell 7'\u001b[0m in \u001b[0;36mprocess_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000006?line=17'>18</a>\u001b[0m \u001b[39m# 색 변경\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000006?line=18'>19</a>\u001b[0m img_hsv \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2HSV)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000006?line=20'>21</a>\u001b[0m img_hsv \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mfastNlMeansDenoisingColored(img_hsv,\u001b[39mNone\u001b[39;49;00m,\u001b[39m10\u001b[39;49m,\u001b[39m10\u001b[39;49m,\u001b[39m7\u001b[39;49m,\u001b[39m21\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000006?line=21'>22</a>\u001b[0m lower \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m,\u001b[39m48\u001b[39m,\u001b[39m80\u001b[39m], dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hongseongmin/Documents/GitHub/jeju_AI/Processing_data.ipynb#ch0000006?line=22'>23</a>\u001b[0m upper \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m20\u001b[39m,\u001b[39m255\u001b[39m,\u001b[39m255\u001b[39m], dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_data(path):\n",
    "    x = []\n",
    "    y = []\n",
    "    dir_list = os.listdir(path)\n",
    "    #print(os.listdir(path))\n",
    "    for i in range(0,len(dir_list)-1):\n",
    "        # if i == 1:\n",
    "        #     break\n",
    "        dir_path = path + \"/\" + dir_list[i+1]\n",
    "        #print(os.listdir(dir_path))\n",
    "        dir_name = os.listdir(dir_path)\n",
    "        \n",
    "        for j in range(len(dir_name)):\n",
    "            \n",
    "            full_dir_path = dir_path + \"/\" + dir_name[j]\n",
    "            print(full_dir_path)\n",
    "            img = cv2.imread(full_dir_path,cv2.IMREAD_COLOR)\n",
    "            # 색 변경\n",
    "            img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            img_hsv = cv2.fastNlMeansDenoisingColored(img_hsv,None,10,10,7,21)\n",
    "            lower = np.array([0,48,80], dtype=\"uint8\")\n",
    "            upper = np.array([20,255,255], dtype=\"uint8\")\n",
    "            img_hand = cv2.inRange(img_hsv,lower,upper)\n",
    "            \n",
    "\n",
    "            #경계선 찾음\n",
    "            contours, hierarchy = cv2.findContours(img_hand, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            # 가장 큰 영역 찾기\n",
    "            max = 0\n",
    "            maxcnt = None\n",
    "            for cnt in contours :\n",
    "                area = cv2.contourArea(cnt)\n",
    "                if(max < area) :\n",
    "                    max = area\n",
    "                    maxcnt = cnt\n",
    "                    if maxcnt.all() == None:\n",
    "                        break\n",
    "            #print(maxcnt)\n",
    "            \n",
    "            mask = np.zeros(img.shape).astype(img.dtype)\n",
    "            # 경계선 내부 255로 채우기\n",
    "            color = [255, 255, 255]\n",
    "            cv2.fillPoly(mask, [maxcnt], color)\n",
    "            img_hand = cv2.bitwise_and(img, mask)\n",
    "            \n",
    "            \n",
    "            mask = cv2.resize(mask, (700,500))\n",
    "            cv2.imwrite('image.png', mask)\n",
    "            x.append(mask)\n",
    "            y.append(i)\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    return np.array(x),np.array(y)\n",
    "\n",
    "process_data(\"./data_image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a824ee367f763222debbf8647112c6fddbe2c594f038468b960687464ff8a91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
